{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bd524b56-21ab-49cc-8efb-84463f2d79f9",
      "metadata": {
        "id": "bd524b56-21ab-49cc-8efb-84463f2d79f9"
      },
      "source": [
        "# Deepfake Image Detector Using DL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cf0493e-fce8-470a-86fb-ed9ac0cecb15",
      "metadata": {
        "id": "9cf0493e-fce8-470a-86fb-ed9ac0cecb15"
      },
      "source": [
        "**Download the dataset from Kaggle using kagglehub**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9886b8f6-b918-4784-a398-a834a0c162f8",
      "metadata": {
        "id": "9886b8f6-b918-4784-a398-a834a0c162f8"
      },
      "outputs": [],
      "source": [
        "!pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fa23f11-b256-4fa9-aa2a-fd36fe58775f",
      "metadata": {
        "id": "7fa23f11-b256-4fa9-aa2a-fd36fe58775f"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"manjilkarki/deepfake-and-real-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z4NI6QVnPTpI",
      "metadata": {
        "id": "z4NI6QVnPTpI"
      },
      "source": [
        "You might need to run the above kagglehub cell again to download the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b2b593c-76d5-4403-97cd-0ab3ac48d302",
      "metadata": {
        "id": "3b2b593c-76d5-4403-97cd-0ab3ac48d302"
      },
      "source": [
        "**Import the required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b7cf32-bedd-4de1-afef-1bdd7a0c3274",
      "metadata": {
        "id": "d6b7cf32-bedd-4de1-afef-1bdd7a0c3274"
      },
      "outputs": [],
      "source": [
        "# Core Libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# CNN, CapsNet, and Functional API Tools\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Layer, Lambda, Reshape, BatchNormalization, Softmax\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Xception Model (Transfer Learning)\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Utilities for Handling Image Files and Paths\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6516d5-592a-4fe2-8350-38b5396a493c",
      "metadata": {
        "id": "7d6516d5-592a-4fe2-8350-38b5396a493c"
      },
      "source": [
        "**Load the images from the Train, Validation, and Test directories**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4e3ffe6-14aa-4a6b-b2fa-22ab4fa9e705",
      "metadata": {
        "id": "c4e3ffe6-14aa-4a6b-b2fa-22ab4fa9e705"
      },
      "outputs": [],
      "source": [
        "# Define the paths for Train, Validation, and Test directories\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/manjilkarki/deepfake-and-real-images/versions/1/Dataset\"\n",
        "train_path = os.path.join(dataset_path, 'Train')\n",
        "val_path = os.path.join(dataset_path, 'Validation')\n",
        "test_path = os.path.join(dataset_path, 'Test')\n",
        "\n",
        "# Function to load datasets using TensorFlow's API\n",
        "def load_tf_dataset(data_path, batch_size=32, img_size=(299, 299)):\n",
        "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        data_path,\n",
        "        label_mode='binary',   # For Real/Fake classification\n",
        "        batch_size=batch_size,\n",
        "        image_size=img_size,\n",
        "        shuffle=True  # Shuffle the dataset to improve training performance\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "# Load Train, Validation, and Test datasets\n",
        "train_dataset = load_tf_dataset(train_path)\n",
        "val_dataset = load_tf_dataset(val_path)\n",
        "test_dataset = load_tf_dataset(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18992699-319e-4872-9792-1a4bc3b29709",
      "metadata": {
        "id": "18992699-319e-4872-9792-1a4bc3b29709"
      },
      "outputs": [],
      "source": [
        "# Check class names\n",
        "print(f\"Train Class Names: {train_dataset.class_names}\")\n",
        "print(f\"Validation Class Names: {val_dataset.class_names}\")\n",
        "print(f\"Test Class Names: {test_dataset.class_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c7efda5-18d9-4f03-bfab-94618012cd1a",
      "metadata": {
        "id": "2c7efda5-18d9-4f03-bfab-94618012cd1a"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0675a37a-1eb2-4d3a-989b-a97f79eb4188",
      "metadata": {
        "id": "0675a37a-1eb2-4d3a-989b-a97f79eb4188"
      },
      "source": [
        "**1. Class Distribution Plot**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24f9d0b6-988b-44b7-a3aa-62867e1e8a0c",
      "metadata": {
        "id": "24f9d0b6-988b-44b7-a3aa-62867e1e8a0c"
      },
      "source": [
        "To ensure that the dataset is balanced (i.e., equal or close number of 'Real' and 'Fake' images are present)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9033e05-e85f-4f02-b99f-1b5d934c6c43",
      "metadata": {
        "id": "c9033e05-e85f-4f02-b99f-1b5d934c6c43",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def plot_class_distribution(dataset, dataset_name):\n",
        "    # Collect all labels in a list\n",
        "    labels = []\n",
        "    for _, batch_labels in dataset:\n",
        "        labels.extend(batch_labels.numpy())\n",
        "\n",
        "    # Calculate the count of each class (Real=0, Fake=1)\n",
        "    real_count = labels.count(0)\n",
        "    fake_count = labels.count(1)\n",
        "\n",
        "    # Plot the class distribution\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.bar(['Real', 'Fake'], [real_count, fake_count], color=['skyblue', 'salmon'])\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('No of Images')\n",
        "    plt.title(f'Class Distribution in {dataset_name} Dataset')\n",
        "    plt.show()\n",
        "\n",
        "# Plot class distributions for Train, Validation, and Test datasets\n",
        "plot_class_distribution(train_dataset, \"Train\")\n",
        "plot_class_distribution(val_dataset, \"Validation\")\n",
        "plot_class_distribution(test_dataset, \"Test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88b77fee-3512-4e54-99c3-8edf4acc0994",
      "metadata": {
        "id": "88b77fee-3512-4e54-99c3-8edf4acc0994"
      },
      "source": [
        "From the bar graphs, we can see that the dataset is balanced (number of 'Real' and 'Fake' images are equal)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a86e85d6-69dc-465c-9abe-b8af904f1249",
      "metadata": {
        "id": "a86e85d6-69dc-465c-9abe-b8af904f1249"
      },
      "source": [
        "**2. Display Some Sample Images**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6983a81-c3d4-4667-9fd2-cc06fa9d7e64",
      "metadata": {
        "id": "f6983a81-c3d4-4667-9fd2-cc06fa9d7e64"
      },
      "source": [
        "To confirm that the images are loaded correctly and match their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a50e8fc2-0ed5-4c00-846d-755654160687",
      "metadata": {
        "id": "a50e8fc2-0ed5-4c00-846d-755654160687"
      },
      "outputs": [],
      "source": [
        "def show_samples(dataset, class_names, num_samples=6):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for images, labels in dataset.take(1):\n",
        "        for i in range(num_samples):\n",
        "            ax = plt.subplot(3, 3, i + 1)\n",
        "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "            plt.title(f\"{class_names[int(labels[i])]}\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "# Display 9 samples from the Train dataset\n",
        "show_samples(train_dataset, train_dataset.class_names, num_samples=9)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d37e47d-37dd-4cf8-8d5c-fbee94c6a654",
      "metadata": {
        "id": "9d37e47d-37dd-4cf8-8d5c-fbee94c6a654"
      },
      "source": [
        "**3. Check Image Shapes and Label Types**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f3b46fb-dabd-486e-98a0-3471b38b9226",
      "metadata": {
        "id": "3f3b46fb-dabd-486e-98a0-3471b38b9226"
      },
      "outputs": [],
      "source": [
        "for images, labels in train_dataset.take(1):  # Display the shape of one batch\n",
        "    print(f\"Image batch shape: {images.shape}\")\n",
        "    print(f\"Label batch shape: {labels.shape}\")\n",
        "    print(f\"Label Data Type: {labels.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0a02db6-c433-44d0-8f64-ae0d06413854",
      "metadata": {
        "id": "f0a02db6-c433-44d0-8f64-ae0d06413854"
      },
      "source": [
        "**4. Plot the Pixel Value Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d598da1d-88d5-4fab-a3e5-40b83b383b46",
      "metadata": {
        "id": "d598da1d-88d5-4fab-a3e5-40b83b383b46"
      },
      "outputs": [],
      "source": [
        "def plot_pixel_distribution(dataset):\n",
        "    pixel_values = []\n",
        "    for images, _ in dataset.take(1):\n",
        "        pixel_values.extend(images.numpy().flatten())\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(pixel_values, bins=50, color='coral')\n",
        "    plt.xlabel('Pixel Value')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Pixel Value Distribution')\n",
        "    plt.show()\n",
        "\n",
        "# Plot the pixel distribution for the Train dataset\n",
        "plot_pixel_distribution(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c17233f4-3f7b-46dd-bfec-92ef84f49a03",
      "metadata": {
        "id": "c17233f4-3f7b-46dd-bfec-92ef84f49a03"
      },
      "source": [
        "## Model 1: CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A2ERGbTxbm0q",
      "metadata": {
        "id": "A2ERGbTxbm0q"
      },
      "outputs": [],
      "source": [
        "# Define CNN model architecture\n",
        "def create_cnn_model(input_shape=(299, 299, 3)):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Create an instance of the CNN model\n",
        "cnn_model = create_cnn_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gfjbA_gXbpDH",
      "metadata": {
        "id": "gfjbA_gXbpDH"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "cnn_model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w56mnTfXHcSO",
      "metadata": {
        "id": "w56mnTfXHcSO"
      },
      "outputs": [],
      "source": [
        "# Display the model summary\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HokyM-7zQH6r",
      "metadata": {
        "id": "HokyM-7zQH6r"
      },
      "outputs": [],
      "source": [
        "# Since the dataset is very huge, we are only taking a subset of the Train, Validation and Test datasets\n",
        "subset_size = 15\n",
        "train_subset = train_dataset.take(subset_size)\n",
        "val_subset = val_dataset.take(subset_size)\n",
        "test_subset = test_dataset.take(subset_size)\n",
        "\n",
        "# Apply caching and prefetching for performance\n",
        "train_subset = train_subset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_subset = val_subset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_subset = test_subset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# model training\n",
        "history = cnn_model.fit(train_subset, epochs=5, validation_data=val_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mlQgH-hZjWVu",
      "metadata": {
        "id": "mlQgH-hZjWVu"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, accuracy = cnn_model.evaluate(test_subset)\n",
        "# Results\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1280891-e435-4cff-b1aa-5309c2e0b504",
      "metadata": {
        "id": "c1280891-e435-4cff-b1aa-5309c2e0b504"
      },
      "source": [
        "## Model 2: CapsNets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YJ0R6jXxYBiO",
      "metadata": {
        "id": "YJ0R6jXxYBiO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Custom squash function for non-linear activation\n",
        "def squash(vectors, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "# Capsule Layer with correct batch_dot dimensions\n",
        "class CapsuleLayer(Layer):\n",
        "    def __init__(self, num_capsules, dim_capsule, routings=3, **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsules = num_capsules\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(input_shape[-1], self.num_capsules * self.dim_capsule),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Reshape inputs for correct batch_dot alignment\n",
        "        u_hat = K.dot(inputs, self.kernel)\n",
        "        u_hat = K.reshape(u_hat, (-1, inputs.shape[1], self.num_capsules, self.dim_capsule))\n",
        "\n",
        "        b = K.zeros_like(u_hat[:, :, :, 0])  # Initialize routing logits\n",
        "\n",
        "        # Dynamic routing process\n",
        "        for i in range(self.routings):\n",
        "            c = tf.nn.softmax(b, axis=2)  # Softmax over the num_capsules dimension\n",
        "            s = K.sum(c[..., None] * u_hat, axis=1)  # Weighted sum across capsules\n",
        "            v = squash(s)  # Squash to unit length\n",
        "            if i < self.routings - 1:\n",
        "                b += K.sum(u_hat * v[:, None, :, :], axis=-1)  # Update logits\n",
        "\n",
        "        return v\n",
        "\n",
        "# Define the CapsNet architecture\n",
        "def create_capsnet(input_shape, n_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # First convolutional layer\n",
        "    conv1 = Conv2D(64, (9, 9), strides=2, padding='valid', activation='relu')(inputs)\n",
        "\n",
        "    # Primary Capsule Layer\n",
        "    primary_caps = Conv2D(128, (9, 9), strides=2, padding='valid', activation='relu')(conv1)\n",
        "    primary_caps = Reshape((-1, 8))(primary_caps)\n",
        "\n",
        "    # Capsule Layer with routing\n",
        "    caps_layer = CapsuleLayer(num_capsules=n_classes, dim_capsule=16, routings=3)(primary_caps)\n",
        "\n",
        "    # Output layer: Compute the length of capsule vectors for class probabilities\n",
        "    outputs = Lambda(lambda z: K.sqrt(K.sum(K.square(z), axis=-1)))(caps_layer)\n",
        "\n",
        "    # Add a Dense layer to ensure correct output shape\n",
        "    outputs = Dense(n_classes, activation='softmax')(outputs)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the CapsNet model instance\n",
        "capsnet_model = create_capsnet(input_shape=(299, 299, 3), n_classes=2)\n",
        "# Display the model summary\n",
        "capsnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jPEkGyOxGwiK",
      "metadata": {
        "id": "jPEkGyOxGwiK"
      },
      "outputs": [],
      "source": [
        "# Display the model summary\n",
        "capsnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZvuuKLb9YlMv",
      "metadata": {
        "id": "ZvuuKLb9YlMv"
      },
      "outputs": [],
      "source": [
        "# Prepare data subsets\n",
        "subset_size = 15\n",
        "train_subset = train_dataset.take(subset_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_subset = val_dataset.take(subset_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_subset = test_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Train the CapsNet model\n",
        "history = capsnet_model.fit(train_subset, epochs=5, validation_data=val_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eRwu5ax9Yq9R",
      "metadata": {
        "id": "eRwu5ax9Yq9R"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_subset = test_subset.take(subset_size)\n",
        "loss, accuracy = capsnet_model.evaluate(test_subset)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "726353fc-c32e-44ec-be95-1ea71da18bdf",
      "metadata": {
        "id": "726353fc-c32e-44ec-be95-1ea71da18bdf"
      },
      "source": [
        "## Model 3: Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b6ecec0-7d5f-47ad-8320-a559d78ee41c",
      "metadata": {
        "id": "8b6ecec0-7d5f-47ad-8320-a559d78ee41c"
      },
      "outputs": [],
      "source": [
        "# Load the Xception model with pre-trained weights, excluding the top layers\n",
        "def create_xception_model(input_shape=(299, 299, 3), n_classes=2):\n",
        "    # Load the base model with ImageNet weights and exclude the top layers\n",
        "    base_model = Xception(\n",
        "        weights='imagenet',\n",
        "        include_top=False,  # Exclude fully connected layers\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "\n",
        "    # Freeze the base model layers to retain pre-trained weights\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Add custom top layers for binary classification\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = preprocess_input(inputs)\n",
        "    x = base_model(x, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    outputs = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    # Create the final model\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Return both the full model and the base model for later fine-tuning\n",
        "    return model, base_model\n",
        "\n",
        "# Create the Xception model instance\n",
        "xception_model, base_model = create_xception_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DbCqkM2GGloG",
      "metadata": {
        "id": "DbCqkM2GGloG"
      },
      "outputs": [],
      "source": [
        "# Display the model summary\n",
        "xception_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QGGnyiDpq_V0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGGnyiDpq_V0",
        "outputId": "1ef4c8d7-edb0-4ac0-fa92-c63b456d8957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 30s/step - accuracy: 0.6114 - loss: 0.6715 - val_accuracy: 0.6792 - val_loss: 0.6053\n",
            "Epoch 2/5\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 33s/step - accuracy: 0.8316 - loss: 0.4188 - val_accuracy: 0.6938 - val_loss: 0.5856\n",
            "Epoch 3/5\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 33s/step - accuracy: 0.8788 - loss: 0.3259 - val_accuracy: 0.6917 - val_loss: 0.6109\n",
            "Epoch 4/5\n",
            "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 14s/step - accuracy: 0.9210 - loss: 0.2543"
          ]
        }
      ],
      "source": [
        "# Prepare data subsets for training, validation, and testing\n",
        "subset_size = 15\n",
        "train_subset = train_dataset.take(subset_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_subset = val_dataset.take(subset_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Train the Xception model\n",
        "history = xception_model.fit(train_subset, epochs=5, validation_data=val_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y0KX_ax0ziuE",
      "metadata": {
        "id": "Y0KX_ax0ziuE"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_subset = test_subset.take(subset_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "loss, accuracy = xception_model.evaluate(test_subset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import Conv2D, Input, Reshape, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "# Custom squash function\n",
        "def squash(vectors, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "# Capsule Layer\n",
        "class CapsuleLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_capsules, dim_capsule, routings=3, **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsules = num_capsules\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(input_shape[-1], self.num_capsules * self.dim_capsule),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        u_hat = K.dot(inputs, self.kernel)\n",
        "        u_hat = K.reshape(u_hat, (-1, inputs.shape[1], self.num_capsules, self.dim_capsule))\n",
        "\n",
        "        b = K.zeros_like(u_hat[:, :, :, 0])\n",
        "\n",
        "        for i in range(self.routings):\n",
        "            c = tf.nn.softmax(b, axis=2)\n",
        "            s = K.sum(c[..., None] * u_hat, axis=1)\n",
        "            v = squash(s)\n",
        "            if i < self.routings - 1:\n",
        "                b += K.sum(u_hat * v[:, None, :, :], axis=-1)\n",
        "        return v\n",
        "\n",
        "# Hybrid Model: Xception + CapsNet\n",
        "def create_hybrid_model(input_shape=(299, 299, 3), num_classes=2):\n",
        "    # Xception as feature extractor (without top layers)\n",
        "    base_model = Xception(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = False  # Freeze pretrained layers\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Conv2D(128, (1, 1), activation='relu')(x)  # Feature refinement\n",
        "    x = Flatten()(x)  # Flatten before sending to Capsule Network\n",
        "    x = Reshape((-1, 8))(x)\n",
        "\n",
        "    # Capsule Network\n",
        "    caps_layer = CapsuleLayer(num_capsules=num_classes, dim_capsule=16, routings=3)(x)\n",
        "    output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), axis=-1)))(caps_layer)\n",
        "    output = Dense(num_classes, activation='softmax')(output)  # Final classification\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "hybrid_model = create_hybrid_model()\n",
        "hybrid_model.summary()\n"
      ],
      "metadata": {
        "id": "I_idg76B-UXj"
      },
      "id": "I_idg76B-UXj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape, Lambda\n",
        "from tensorflow.keras import Model\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Custom squash function\n",
        "def squash(vectors, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "# Capsule Layer\n",
        "class CapsuleLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_capsules, dim_capsule, routings=3, **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsules = num_capsules\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(input_shape[-1], self.num_capsules * self.dim_capsule),\n",
        "            initializer=\"glorot_uniform\",\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        u_hat = K.dot(inputs, self.kernel)\n",
        "        u_hat = K.reshape(u_hat, (-1, inputs.shape[1], self.num_capsules, self.dim_capsule))\n",
        "\n",
        "        b = K.zeros_like(u_hat[:, :, :, 0])\n",
        "        for i in range(self.routings):\n",
        "            c = tf.nn.softmax(b, axis=2)\n",
        "            s = K.sum(c[..., None] * u_hat, axis=1)\n",
        "            v = squash(s)\n",
        "            if i < self.routings - 1:\n",
        "                b += K.sum(u_hat * v[:, None, :, :], axis=-1)\n",
        "        return v\n",
        "\n",
        "# EfficientNet-based Hybrid Model\n",
        "def create_efficientnet_capsnet(input_shape=(299, 299, 3), num_classes=2):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # EfficientNet feature extractor\n",
        "    base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_tensor=inputs)\n",
        "    base_model.trainable = False  # Freeze EfficientNet layers\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Reshape((-1, 8))(x)  # Reshape to fit Capsule input\n",
        "\n",
        "    # Capsule Network Layer\n",
        "    caps_layer = CapsuleLayer(num_capsules=num_classes, dim_capsule=16, routings=3)(x)\n",
        "    outputs = Lambda(lambda z: K.sqrt(K.sum(K.square(z), axis=-1)))(caps_layer)\n",
        "    outputs = Dense(num_classes, activation=\"softmax\")(outputs)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# Create and summarize the model\n",
        "hybrid_model = create_efficientnet_capsnet()\n",
        "hybrid_model.summary()\n"
      ],
      "metadata": {
        "id": "kcq6WjY3-qRB"
      },
      "id": "kcq6WjY3-qRB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(hybrid_model, to_file=\"hybrid_model.png\", show_shapes=True, show_layer_names=True)\n"
      ],
      "metadata": {
        "id": "oIcUl7zYUkny"
      },
      "id": "oIcUl7zYUkny",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def configure_dataset(dataset):\n",
        "    return dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "train_dataset = configure_dataset(train_dataset)\n",
        "val_dataset = configure_dataset(val_dataset)\n",
        "test_dataset = configure_dataset(test_dataset)\n"
      ],
      "metadata": {
        "id": "Xm1BkdFqU4F3"
      },
      "id": "Xm1BkdFqU4F3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.take(1000)  # Use only 1000 batches\n",
        "val_dataset = val_dataset.take(500)  # Use only 500 batches\n"
      ],
      "metadata": {
        "id": "y5p9FGPBVqT_"
      },
      "id": "y5p9FGPBVqT_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = load_tf_dataset(train_path, batch_size=64)\n",
        "val_dataset = load_tf_dataset(val_path, batch_size=64)\n",
        "test_dataset = load_tf_dataset(test_path, batch_size=64)\n"
      ],
      "metadata": {
        "id": "FspzxHoCV9t2"
      },
      "id": "FspzxHoCV9t2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_img(img, label):\n",
        "    img = tf.image.resize(img, (299, 299)) / 255.0  # Normalize images\n",
        "    return img, label\n",
        "\n",
        "def load_tf_dataset(data_path, batch_size=32):\n",
        "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        data_path,\n",
        "        label_mode='binary',\n",
        "        batch_size=batch_size,\n",
        "        image_size=(299, 299),\n",
        "        shuffle=True\n",
        "    ).map(process_img, num_parallel_calls=tf.data.AUTOTUNE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "z9444JRgWD_2"
      },
      "id": "z9444JRgWD_2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True  # Unfreeze EfficientNet\n",
        "for layer in base_model.layers[:-50]:  # Freeze first 50 layers\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "9Nf0U_AiWIqC"
      },
      "id": "9Nf0U_AiWIqC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape, Lambda\n",
        "from tensorflow.keras import Model\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Custom squash function\n",
        "def squash(vectors, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "# Capsule Layer\n",
        "class CapsuleLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_capsules, dim_capsule, routings=3, **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsules = num_capsules\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(input_shape[-1], self.num_capsules * self.dim_capsule),\n",
        "            initializer=\"glorot_uniform\",\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        u_hat = K.dot(inputs, self.kernel)\n",
        "        u_hat = K.reshape(u_hat, (-1, inputs.shape[1], self.num_capsules, self.dim_capsule))\n",
        "        b = K.zeros_like(u_hat[:, :, :, 0])\n",
        "        for i in range(self.routings):\n",
        "            c = tf.nn.softmax(b, axis=2)\n",
        "            s = K.sum(c[..., None] * u_hat, axis=1)\n",
        "            v = squash(s)\n",
        "            if i < self.routings - 1:\n",
        "                b += K.sum(u_hat * v[:, None, :, :], axis=-1)\n",
        "        return v\n",
        "\n",
        "# Updated EfficientNet-based Hybrid Model with input_shape=(224, 224, 3)\n",
        "def create_efficientnet_capsnet(input_shape=(224, 224, 3), num_classes=2):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # EfficientNetB0 as feature extractor (default input shape for pretrained weights is 224x224)\n",
        "    base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_tensor=inputs)\n",
        "    base_model.trainable = False  # Freeze EfficientNet layers\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Reshape((-1, 8))(x)  # Adjust reshaping if necessary based on new dimensions\n",
        "\n",
        "    # Capsule Network Layer\n",
        "    caps_layer = CapsuleLayer(num_capsules=num_classes, dim_capsule=16, routings=3)(x)\n",
        "    outputs = Lambda(lambda z: K.sqrt(K.sum(K.square(z), axis=-1)))(caps_layer)\n",
        "    outputs = Dense(num_classes, activation=\"softmax\")(outputs)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# Re-create the hybrid model with the new input shape\n",
        "hybrid_model = create_efficientnet_capsnet()\n",
        "hybrid_model.summary()\n"
      ],
      "metadata": {
        "id": "Pu49rvpNWNex"
      },
      "id": "Pu49rvpNWNex",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = load_tf_dataset(test_path, batch_size=32)\n",
        "\n"
      ],
      "metadata": {
        "id": "3sjNoDHDuv0j"
      },
      "id": "3sjNoDHDuv0j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the last 20 layers  the EfficientNet base model\n",
        "for i, layer in enumerate(hybrid_model.layers):\n",
        "    print(i, layer.name, layer.__class__.__name__)\n",
        "\n",
        "# Recompile with a lower learning rate for fine-tuning\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "hybrid_model.compile(optimizer=optimizer,\n",
        "                     loss='sparse_categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "rV8NGPDCyw3Q"
      },
      "id": "rV8NGPDCyw3Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze EfficientNet base layers by checking the layer names\n",
        "for layer in hybrid_model.layers:\n",
        "    if layer.name.startswith(\"stem_\") or layer.name.startswith(\"block\"):\n",
        "        layer.trainable = True\n",
        "\n",
        "# Optionally, print layer names and trainable status to verify\n",
        "for layer in hybrid_model.layers:\n",
        "    print(layer.name, layer.trainable)\n",
        "\n",
        "# Recompile the model with a lower learning rate for fine-tuning\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "hybrid_model.compile(optimizer=optimizer,\n",
        "                     loss='sparse_categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "AuIdtBLDzitv"
      },
      "id": "AuIdtBLDzitv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Define Dataset Paths\n",
        "# -------------------------------\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/manjilkarki/deepfake-and-real-images/versions/1/Dataset\"\n",
        "train_path = os.path.join(dataset_path, 'Train')\n",
        "val_path   = os.path.join(dataset_path, 'Validation')\n",
        "test_path  = os.path.join(dataset_path, 'Test')\n",
        "\n",
        "print(\"Train Path:\", train_path)\n",
        "print(\"Validation Path:\", val_path)\n",
        "print(\"Test Path:\", test_path)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Load and Preprocess Datasets\n",
        "# -------------------------------\n",
        "def load_raw_dataset(data_path, batch_size=32, img_size=(224,224)):\n",
        "    return tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        data_path,\n",
        "        label_mode='binary',   # binary classification: Real vs Fake\n",
        "        batch_size=batch_size,\n",
        "        image_size=img_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "# Load raw datasets first to capture class names\n",
        "raw_train_dataset = load_raw_dataset(train_path, batch_size=32, img_size=(224,224))\n",
        "train_class_names = raw_train_dataset.class_names\n",
        "\n",
        "raw_val_dataset = load_raw_dataset(val_path, batch_size=32, img_size=(224,224))\n",
        "val_class_names = raw_val_dataset.class_names\n",
        "\n",
        "raw_test_dataset = load_raw_dataset(test_path, batch_size=32, img_size=(224,224))\n",
        "test_class_names = raw_test_dataset.class_names\n",
        "\n",
        "# Now apply EfficientNet preprocessing and prefetch\n",
        "def preprocess_dataset(raw_dataset):\n",
        "    return raw_dataset.map(lambda x, y: (preprocess_input(x), y),\n",
        "                           num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset = preprocess_dataset(raw_train_dataset)\n",
        "val_dataset   = preprocess_dataset(raw_val_dataset)\n",
        "test_dataset  = preprocess_dataset(raw_test_dataset)\n",
        "\n",
        "print(\"Train Classes:\", train_class_names)\n",
        "print(\"Validation Classes:\", val_class_names)\n",
        "print(\"Test Classes:\", test_class_names)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Define the CNN+BiLSTM Model\n",
        "# -------------------------------\n",
        "input_shape = (224, 224, 3)\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "# Use EfficientNetB0 as a feature extractor\n",
        "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_tensor=inputs)\n",
        "base_model.trainable = False  # Freeze the backbone\n",
        "\n",
        "# Extract features (expected shape: (None, H, W, channels), e.g., (None, 7, 7, 1280))\n",
        "x = base_model.output\n",
        "shape = tf.keras.backend.int_shape(x)  # e.g., (None, 7, 7, 1280)\n",
        "\n",
        "# Reshape to a sequence for the LSTM: (batch, time_steps, features)\n",
        "x = layers.Reshape((shape[1] * shape[2], shape[3]))(x)  # (None, 7*7=49, 1280)\n",
        "\n",
        "# Process the sequence with a Bidirectional LSTM\n",
        "x = layers.Bidirectional(layers.LSTM(128, return_sequences=False))(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Final classification layer for 2 classes: Real and Fake\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "# Build and compile the model\n",
        "bilstm_model = models.Model(inputs=inputs, outputs=outputs)\n",
        "bilstm_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "bilstm_model.summary()\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Train the Model\n",
        "# -------------------------------\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "]\n",
        "\n",
        "history_bilstm = bilstm_model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=700,              # Adjust epochs as needed\n",
        "    steps_per_epoch=50,     # Adjust based on your dataset size\n",
        "    validation_steps=10,     # Adjust accordingly\n",
        "    # callbacks=callbacks\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Evaluate the Model\n",
        "# -------------------------------\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = np.argmax(bilstm_model.predict(test_dataset), axis=1)\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "print(\"Classification Report for CNN+BiLSTM Model:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Real', 'Fake']))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Plot Training History\n",
        "# -------------------------------\n",
        "def plot_training_history(history, title=\"CNN+BiLSTM Training History\"):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title(title + \" - Accuracy\")\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title(title + \" - Loss\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history_bilstm)\n"
      ],
      "metadata": {
        "id": "IGAN6UqH847n"
      },
      "id": "IGAN6UqH847n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}